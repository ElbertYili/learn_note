{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本结构\n",
    "\n",
    "    首先定义神经网络的结构（节点），然后数据填充进结构中运算和training\n",
    "   使用data Flow graphs来计算。\n",
    "    数据以**tensor**的形式存在,float32格式比64位的快很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Session\n",
    "    Session是TensorFlow控制和输出文件的执行者\n",
    "    通过session.run()可以进行运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# method 1\n",
    "sess = tf.Session()\n",
    "x = tf.Variable(3, name='X')\n",
    "y = tf.Variable(4, name='Y')\n",
    "f = x * y + 4 * y\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()\n",
    "# [[12]]\n",
    "\n",
    "# method 2\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    sess.run(y.initializer)\n",
    "    result2 = sess.run(f)\n",
    "    print(result2)\n",
    "# [[12]]\n",
    "\n",
    "# method 3\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result2 = f.eval()\n",
    "    print(result2)\n",
    "    \n",
    "# method 4\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result2 = f.eval()\n",
    "    print(result2)\n",
    "    \n",
    "# method 5\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result2 = f.eval()\n",
    "print(result2)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variable\n",
    "    必须定义成变量才是Variable\n",
    "    一定要初始化\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "counter_12:0\n",
      "Tensor(\"Add_7:0\", shape=(), dtype=int32)\n",
      "<tensorflow.python.ops.variables.Variable object at 0x118019cd0>\n",
      "Tensor(\"Assign_7:0\", shape=(), dtype=int32_ref)\n"
     ]
    }
   ],
   "source": [
    "# counter是个名字标签\n",
    "state = tf.Variable(0, name='counter')\n",
    "# 定义一个常量\n",
    "one = tf.constant(1)\n",
    "\n",
    "# 做一个加法运算\n",
    "new = tf.add(state, one)\n",
    "# 将new的值更新到state上,否则state的值在add\n",
    "# 之后并不会变更\n",
    "update = tf.assign(state, new)\n",
    "\n",
    "# 定义了变量就一定要初始化才能用\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        #这样就会调用到new的节点运算，猜测根据图结构，完成\n",
    "        print(sess.run(state))\n",
    "\n",
    "print state.name\n",
    "print new\n",
    "print state\n",
    "print update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Placeholder\n",
    "   Tensorflow中的占位符,一个大特点就是**不用初始化操作**\n",
    "   外部传入data时，以这种形式传输数据 sess.run(***, feed_dict={input: **})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.20000029]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.mul(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict={input1:[7.], input2:[.6]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 激励函数\n",
    "    在Tensorflow中激励函数一般在隐藏层中\n",
    "    Tensorflow内置了很多激励函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.sigmoid>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 优化器——Optimizer\n",
    "    Tensorflow常用Optimizer\n",
    "![常用的几种](https://morvanzhou.github.io/static/results/tensorflow/3_4_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# 节点的生命周期\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  # 10,  y依赖x， x依赖w，所以x和w的节点会被创建，并在结束计算的时候销毁，所以在整个session里x和w被建立了两次\n",
    "    print(z.eval())  # 15， 而通过初始化的变量会在session关闭之前一直存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing_data_plus_bias (20640, 9)\n",
      "theta_value [[ -3.74651413e+01]\n",
      " [  4.35734153e-01]\n",
      " [  9.33829229e-03]\n",
      " [ -1.06622010e-01]\n",
      " [  6.44106984e-01]\n",
      " [ -4.25131839e-06]\n",
      " [ -3.77322501e-03]\n",
      " [ -4.26648885e-01]\n",
      " [ -4.40514028e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 使用TensorFlow 做线性回归\n",
    "# 方程：theta = (XT · X)–1 · XT · y;\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "tf.reset_default_graph()\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "print('housing_data_plus_bias', housing_data_plus_bias.shape)\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print('theta_value', theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 常用的Optimizer\n",
    "tf.train.AdamOptimizer\n",
    "tf.train.GradientDescentOptimizer\n",
    "tf.train.MomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
