# 卷积神经网络基本概念

卷积神经网络（ConNets或者CNNs）

## LeNet架构

* 四个主要操作

  * 卷积

    * 深度

      对应滤波器的个数，即使用的核的个数

      可以对输入图形做多个卷积处理

    * 步长

    * 零填充

      泛卷积		严格卷积

  * 非线性处理（ReLU）

    ReLU 是一个元素级别的操作（应用到各个像素），并将特征图中的所有小于 0 的像素值设置为零。ReLU 的目的是在 ConvNet 中引入非线性，因为在大部分的我们希望 ConvNet 学习的实际数据是非线性的（卷积是一个线性操作——元素级别的矩阵相乘和相加，所以我们需要通过使用非线性函数 ReLU 来引入非线性

  * 池化或者亚采样

    空间池化（Spatial Pooling）（也叫做亚采用或者下采样）降低了各个特征图的维度，但可以保持大部分重要的信息。空间池化有下面几种方式：**最大化**、平均化、加和等等。

    其中最大池化效果更好

    目的：

    1. 使输入表示（特征维度）变得更小，并且网络中的参数和计算的数量更加可控的减小，因此，可以控制过拟合
    2. 使网络对于输入图像中更小的变化、冗余和变换变得不变性（输入的微小冗余将不会改变池化的输出——因为我们在局部邻域中使用了最大化/平均值的操作。
    3. 帮助我们获取图像最大程度上的尺度不变性（准确的词是“不变性”）

  * 分类

    * 全连接层
    * 分类器
    * ​

### 全连接层

* 概念

  ​“全连接（Fully Connected）”这个词表明前面层的所有神经元都与下一层的所有神经元连接

  ​卷积和池化层的输出表示了输入图像的高级特征。全连接层的目的是为了使用这些特征把输入图像基于训练数据集进行分类

* 使用反向传播进行训练

